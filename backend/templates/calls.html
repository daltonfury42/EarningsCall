<!DOCTYPE html>
<html lang="en">

<head>
  <!-- Required meta tags -->
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

  <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/css/bootstrap.min.css"
    integrity="sha384-Gn5384xqQ1aoWXA+058RXPxPg6fy4IWvTNh0E263XmFcJlSAwiGgFAW/dAiS6JXm" crossorigin="anonymous">
  <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
  <link rel="stylesheet" href="{{ url_for('static', filename='css/custom.css') }}" type="text/css">
</head>

<body>
  <nav class="navbar navbar-expand-md navbar-dark fixed-top bg-dark">
    <a class="navbar-brand" href="https://www.morganstanley.com">Morgan Stanley</a>
  </nav>
  <main role="main">
    <div class="block-centered">
      <h1 class="text-centered">Contextual Emotion Mining on Earning Calls</h1>
      <br><br>
      <p class="text-centered">Analysis of earnings call audio to help research analysts to analyse sentiment about
        the company along with relevant topics. This provides important insights on how the bussiness is performing.
        It saves considerable amount of time for the analysts without having to listen to every call.
      </p>
    </div>
    <div class="container-fluid">
      <div class="row justify-content-center text-center">
        <div class="col-sm-12 align-self-center">
            <br><br>
          <div class="list-group list-group-flush" style="display:inline-block;">
            {% for data in dataList %}
            <a href="/call/{{ data['callId'] }}" class="list-group-item list-group-item-action flex-column align-items-start">
    <div class="d-flex w-100 justify-content-between">
      <p class="mb-1">{{ data['title'] }} &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp; &nbsp;</p>
      <span class="dot-{{ data['color'] }}"></span>
    </div></a>
            {% endfor %}
          </div>
        </div>

      </div>
    </div>
  </main>

  <script src="https://code.jquery.com/jquery-3.2.1.slim.min.js"
    integrity="sha384-KJ3o2DKtIkvYIK3UENzmM7KCkRr/rE9/Qpg6aAZGJwFDMVNA/GpGFF93hXpG5KkN"
    crossorigin="anonymous"></script>
  <script src="https://cdnjs.cloudflare.com/ajax/libs/popper.js/1.12.9/umd/popper.min.js"
    integrity="sha384-ApNbgh9B+Y1QKtv3Rn7W3mgPxhU9K/ScQsAP7hUibX39j7fakFPskvXusvfa0b4Q"
    crossorigin="anonymous"></script>
  <script src="https://maxcdn.bootstrapcdn.com/bootstrap/4.0.0/js/bootstrap.min.js"
    integrity="sha384-JZR6Spejh4U02d8jOt6vLEHfe/JQGiRRSQQxSfFWpi1MquVdAyjUar5+76PVCmYl"
    crossorigin="anonymous"></script>
  <!-- 
	  Hierarchial Attention Networks â€“ An intersection of Deep Learning and Natural Language Processing

Long Short Term Memory (LSTM) is a type of Recurrent Neural Network (RNN) that works well on sequence data. The network has memory, ie the previous sequnces it had encountered is used to make more accurate predictions compared to traditional feedforward neural networks. Since LSTMs can capture temporal aspect of input, it is well suited for classification of text, video and other time series data. Hierarchial Attention Networks (HAN) build on top of RNNs and learns the imporatant data points that contibute to the results of the network.

Text documents have a hierarchial structure where the document is a collection of sentences, and each senteces are collections of words. At the sentence level, an LSTM layer is used to classify each sentence by processing the sequence of words. An attention layer takes as input the weights of this LSTM layer and uses it to find the important words in the sentence. The next layer of LSTM? works at the sentence level and the sentence level attention layer on top of it again assigns attention weights to the sentences according to their importance. This way we can extract important words and senteces in a document.

This approach was tested on Earnings Call transcripts of companies in the semiconductor industry and the results can be viewed at df42.sandcats.io?

Autoencoder?
  
  --> 
</body>

</html>
